{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzrS1a-L5ETo"
      },
      "source": [
        "# Image Neighborhoods and Clustering of Street Artwork\n",
        "#### Author: Antonio Rueda-Toicen\n",
        "**antonio.rueda.toicen 'at' hpi 'dot' de**\n",
        "\n",
        "\n",
        "This tutorial is part 3 of a series on image similarity. Refer to the [previous notebook](https://colab.research.google.com/drive/1yR4e3OVXe_QqCIYkmDhcT75300P9Db1H#scrollTo=c8520ef2) to get the image embeddings.\n",
        "\n",
        "The folder with the downloaded images is available [here](https://drive.google.com/drive/folders/1l7VvTnRwWpo4_wPPMrUcmMtKeaxuFTfY?usp=drive_link). Right click on the folder name and select \"Add Shortcut to Drive\" in order to add to your own Drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56953925"
      },
      "source": [
        "## Intro\n",
        "\n",
        "Image embeddings, similarity metrics, and clustering on it are powerful techniques used in various domains, including **image analysis, recommendation systems, and data cleaning**. In this notebook, we'll explore how to use image similarity metrics to analyze and clean a dataset of artworks.\n",
        "\n",
        "### Image Similarity\n",
        "Image similarity measures how alike two images are and can be used to identify duplicates, variations, or related works within a dataset. It's an important step in preparing a clean and coherent dataset for further analysis or machine learning tasks. When building machine learning models, it's particularly important for us to eliminate duplicates between test and training sets, as this creates issues with [data leakage](https://en.wikipedia.org/wiki/Leakage_(machine_learning)#:~:text=In%20statistics%20and%20machine%20learning,when%20run%20in%20a%20production), meaning that we can't trust the accuracy that the model reports.\n",
        "\n",
        "### Image Clustering\n",
        "When we ['cluster'](https://en.wikipedia.org/wiki/Cluster_analysis#:~:text=Cluster%20analysis%20or%20clustering%20is,in%20other%20groups%20(clusters).) data, we break into groups. We use a measure of similarity to do this division.\n",
        "\n",
        " When applying a clustering algorithm to image embeddings we group similar images together, creating groups of related content. It helps in understanding the underlying patterns, themes, or categories within a dataset. Clustering can reveal insights into the artistic styles, subjects, or other common features among the images.\n",
        "\n",
        "### K-Medoids Algorithm\n",
        "In this notebook, we'll use the [k-medoids algorithm](https://en.wikipedia.org/wiki/K-medoids), a robust clustering method that partitions the dataset into 'k' clusters. Unlike [k-means](https://en.wikipedia.org/wiki/K-means_clustering), k-medoids choose actual data points as cluster centers (medoids), making it less sensitive to outliers.\n",
        "\n",
        "As the medoids are actual data points, they are the representatives of their clusters.\n",
        "\n",
        "The animation below shows how the K-medoids algorithm converges to a solution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOJn20Ly3A0K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFnLZs_lc_JY"
      },
      "source": [
        "![](https://upload.wikimedia.org/wikipedia/commons/e/e1/K-Medoids_Clustering.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPK_6N2dcZYT"
      },
      "source": [
        "We'll apply k-medoids to explore the dataset and find the most representative works of the artist Bansky.\n",
        "\n",
        "Let's dive into the process and begin with mounting Google Drive to access the necessary files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bfa85dd"
      },
      "source": [
        "## 1. Mounting Google Drive\n",
        "\n",
        "In this section, we mount Google Drive to the Colab environment. This allows us to access files and data stored in Google Drive, which is essential if we are working with datasets or other resources stored there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqhy7IPvIZeS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb72a853"
      },
      "source": [
        "## 2. Importing Libraries and Setting Paths\n",
        "\n",
        "We begin by importing the necessary libraries that enable us to handle images, perform clustering, and conduct other related tasks. Next, we define the paths to the folders containing the images and data we will work with. Organizing paths helps us manage files efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnISoK8wIbH8"
      },
      "outputs": [],
      "source": [
        "# We use pathlib to ease the manipulation of filenames and paths in Google Drive\n",
        "import os\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaW7t75pXe4W"
      },
      "source": [
        "## 3. Reading and Validating Files\n",
        "\n",
        "In this part, we read the necessary files, including image embeddings, and validate them to ensure that they are in the correct format. Validation helps in detecting and handling potential issues early in the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDH9tjVjLCNX"
      },
      "outputs": [],
      "source": [
        "path = Path('/gdrive/MyDrive/art_recommendation')\n",
        "artist = 'banksy'\n",
        "folder_path = path / artist\n",
        "os.listdir(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX1P3Zq3NLUA"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(folder_path / 'paintings_embeddings.pickle', 'rb') as handle:\n",
        "  paintings_embeddings = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7q8YZzxNyyy"
      },
      "outputs": [],
      "source": [
        "len(paintings_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-lusxI7N00x"
      },
      "outputs": [],
      "source": [
        "list_of_painting_names = os.listdir(folder_path / 'paintings')\n",
        "# Check that we can read the proper paths to the images\n",
        "full_paths_to_images = [folder_path / 'paintings' / painting for painting in list_of_painting_names ]\n",
        "full_paths_to_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3eT9VtSR4ir"
      },
      "outputs": [],
      "source": [
        "# Check the individual file names\n",
        "os.listdir(folder_path / 'paintings')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECJCuyJcRJYw"
      },
      "outputs": [],
      "source": [
        "# Check that we can open a particular image from Google Drive\n",
        "from PIL import Image\n",
        "Image.open(full_paths_to_images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut42bbcERcBx"
      },
      "outputs": [],
      "source": [
        "# Check that the keys of the dictionary contain image paths\n",
        "Image.open(list(paintings_embeddings.keys())[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJtxO_0gPNro"
      },
      "outputs": [],
      "source": [
        "# Check the number of paintings in our dataset\n",
        "paintings_to_visualize = {painting:embedding for painting, embedding in paintings_embeddings.items() if painting in full_paths_to_images}\n",
        "len(paintings_to_visualize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s5nVVDqXWSm"
      },
      "source": [
        "## Visualize Pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5GNuGK3MzX0"
      },
      "source": [
        "\n",
        "Visualizing pairs of images can provide insights into the similarities and differences between them. This step often helps in understanding the characteristics of the images and how they relate to each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLDRtIvOPwZE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "  return dot(a, b)/(norm(a)*norm(b))\n",
        "\n",
        "def print_cosine_similarity(embedding_a, embedding_b):\n",
        "  cos = cosine_similarity(embedding_a, embedding_b)\n",
        "  result = f'Cosine similarity = {cos:.2f}'\n",
        "  print(result)\n",
        "\n",
        "def show_pair(imag_a, imag_b):\n",
        "  plt.subplot(121)\n",
        "  plt.imshow(np.array(imag_a))\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  plt.subplot(122)\n",
        "  plt.imshow(np.array(imag_b))\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NH0UcgAudqoS"
      },
      "outputs": [],
      "source": [
        "len(paintings_to_visualize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7X-q04_duDK"
      },
      "outputs": [],
      "source": [
        "# We create double slider to visualize the similarity between every two images\n",
        "# in the dataset\n",
        "image_index_a = 221  #@param {type: \"slider\", min: 0, max: 317, step:1}\n",
        "\n",
        "image_index_b = 61  #@param {type: \"slider\", min: 0, max: 317, step:1}\n",
        "\n",
        "embed_a = list(paintings_to_visualize.values())[image_index_a]\n",
        "embed_b = list(paintings_to_visualize.values())[image_index_b]\n",
        "image_a = Image.open(list(paintings_to_visualize.keys())[image_index_a])\n",
        "image_b = Image.open(list(paintings_to_visualize.keys())[image_index_b])\n",
        "\n",
        "print_cosine_similarity(embed_a, embed_b)\n",
        "show_pair(image_a, image_b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrXQOcoY-P6N"
      },
      "source": [
        "## Find Clusters of the Most Similar Images\n",
        "\n",
        "Exploring the dataset looking at the 9 nearest neighbors of each image will allow us to understand it better and to check for duplicates. Note that the closest 'neighbor' to every image is itself. It's cosine similarity should be 1.0 (or very-very-very close to 1.0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00371720"
      },
      "source": [
        "## 5. Calculating and Visualizing Cosine Similarity\n",
        "\n",
        "In this section, we calculate the cosine similarity between images, which helps us understand how similar two images are. We also include code to visualize the similarity between different pairs of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQEjaYh8lHG9"
      },
      "outputs": [],
      "source": [
        "# Separate vectors and image filenames (for convenience)\n",
        "X = []\n",
        "images = []\n",
        "for image, embedding in paintings_embeddings.items():\n",
        "    X.append(embedding)\n",
        "    images.append(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J762_bHuCdP"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "nbrs = NearestNeighbors(n_neighbors=9, metric='cosine').fit(X)\n",
        "nbrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnGkM_zXlSVJ"
      },
      "outputs": [],
      "source": [
        "# Get the distances between neighbohoods and the indices of similarity\n",
        "neighbor_distances, neighbor_indices = nbrs.kneighbors(X)\n",
        "neighbor_similarities = 1 - neighbor_distances\n",
        "neighbor_similarities, neighbor_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7P-2q7736Zx"
      },
      "source": [
        "\n",
        "Clustering is the process of grouping similar objects together. In this section, we apply clustering techniques to group images that are similar to each other. This can help in understanding the relationships between different images and identifying patterns within the dataset. In this case, we are interested in finding which are the most representative artworks in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oRKEQsvuuMt"
      },
      "outputs": [],
      "source": [
        "# We use this code to restructure the dataset and get indices of most similar images\n",
        "neighborhoods_dict = {}\n",
        "for i in range(len(neighbor_indices)):\n",
        "    center_image = images[neighbor_indices[i, 0]]\n",
        "    neighbors_list = []\n",
        "    for j in range(0, len(neighbor_indices[0])):\n",
        "        neighbor_image = images[neighbor_indices[i][j]]\n",
        "        neighbor_similarity = round(neighbor_similarities[i][j],2)\n",
        "        neighbors_list.append([neighbor_image, neighbor_similarity])\n",
        "    neighborhoods_dict[center_image] = neighbors_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYPyllvvlpoB"
      },
      "outputs": [],
      "source": [
        "paintings_with_full_path = list(neighborhoods_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlUeeGq2awJ_"
      },
      "outputs": [],
      "source": [
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_neighborhood(neighbors_row):\n",
        "  \"\"\"\n",
        "    This function allows us to visualize the 9 nearest neighbors of every image in\n",
        "    the dataset.\n",
        "    We see the cosine similarity between the query image and its neighbors\n",
        "    in the title of each plot.\n",
        "  \"\"\"\n",
        "  f, axarr = plt.subplots(3,3, figsize=(15,15))\n",
        "\n",
        "  axarr[0][0].imshow(io.imread(folder_path /'paintings' / neighbors_row[0][0]))\n",
        "  axarr[0][1].imshow(io.imread(folder_path /'paintings' / neighbors_row[1][0]))\n",
        "  axarr[0][2].imshow(io.imread(folder_path /'paintings' / neighbors_row[2][0]))\n",
        "  axarr[1][0].imshow(io.imread(folder_path /'paintings' / neighbors_row[3][0]))\n",
        "  axarr[1][1].imshow(io.imread(folder_path /'paintings' / neighbors_row[4][0]))\n",
        "  axarr[1][2].imshow(io.imread(folder_path /'paintings' / neighbors_row[5][0]))\n",
        "  axarr[2][0].imshow(io.imread(folder_path /'paintings' / neighbors_row[6][0]))\n",
        "  axarr[2][1].imshow(io.imread(folder_path /'paintings' / neighbors_row[7][0]))\n",
        "  axarr[2][2].imshow(io.imread(folder_path /'paintings' / neighbors_row[8][0]))\n",
        "\n",
        "  axarr[0, 0].set_title(neighbors_row[0][1])\n",
        "  axarr[0, 1].set_title(neighbors_row[1][1])\n",
        "  axarr[0, 2].set_title(neighbors_row[2][1])\n",
        "  axarr[1, 0].set_title(neighbors_row[3][1])\n",
        "  axarr[1, 1].set_title(neighbors_row[4][1])\n",
        "  axarr[1, 2].set_title(neighbors_row[5][1])\n",
        "  axarr[2, 0].set_title(neighbors_row[6][1])\n",
        "  axarr[2, 1].set_title(neighbors_row[7][1])\n",
        "  axarr[2, 2].set_title(neighbors_row[8][1])\n",
        "\n",
        "  for i in range(3):\n",
        "        for j in range(3):\n",
        "            axarr[i, j].axis('off')\n",
        "\n",
        "plot_neighborhood(neighborhoods_dict[paintings_with_full_path[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHSc12zc-tB6"
      },
      "outputs": [],
      "source": [
        "# @title Visualizing Image Neighborhoods with a Slider Widget {run:'auto'}\n",
        "\n",
        "slider_value = 223  #@param {type: \"slider\", min: 0, max: 317}\n",
        "plot_neighborhood(neighborhoods_dict[paintings_with_full_path[slider_value]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRjoq9tRSXjo"
      },
      "source": [
        "## De-duplicating the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEUtWd-o3Ely"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Assuming `image_embeddings` is your dictionary: keys are image paths, and values are embeddings\n",
        "image_embeddings = paintings_embeddings.copy()\n",
        "\n",
        "# Convert embeddings to a Tensor for batch computation of cosine similarity\n",
        "embeddings_tensor = np.stack(list(image_embeddings.values()))\n",
        "\n",
        "# Compute pairwise cosine similarity\n",
        "# For large numbers of embeddings, consider doing this in smaller batches to avoid memory issues\n",
        "cos_sim_matrix = cosine_similarity(embeddings_tensor)\n",
        "\n",
        "# Generate all pairs of image paths\n",
        "image_paths = list(image_embeddings.keys())\n",
        "pairs = [(image_paths[i], image_paths[j], cos_sim_matrix[i, j])\n",
        "         for i in range(len(image_paths))\n",
        "         for j in range(i+1, len(image_paths))]  # i+1 to avoid self-comparison\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(pairs, columns=['image_a_path', 'image_b_path', 'cosine_similarity'])\n",
        "\n",
        "# Show the DataFrame (or save to CSV, etc.)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG0fEWCH3QtH"
      },
      "outputs": [],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TltaXXR3if8"
      },
      "outputs": [],
      "source": [
        "len(paintings_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyjPbUye3qy7"
      },
      "outputs": [],
      "source": [
        "import skimage.io as io\n",
        "\n",
        "def show_pair(imag_a, imag_b):\n",
        "  plt.subplot(121)\n",
        "  plt.imshow(np.array(imag_a))\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  plt.subplot(122)\n",
        "  plt.imshow(np.array(imag_b))\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "\n",
        "print(df.iloc[0].cosine_similarity)\n",
        "show_pair(io.imread(df.iloc[0].image_a_path), io.imread(df.iloc[0].image_b_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggoJws7A9c-j"
      },
      "outputs": [],
      "source": [
        "# Sort the DataFrame by 'cosine_similarity' in descending order\n",
        "df_sorted = df.sort_values(by='cosine_similarity', ascending=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwTdxkMH4jkw"
      },
      "outputs": [],
      "source": [
        "# @title {run:'auto'}\n",
        "\n",
        "\n",
        "slider_value = 12  # @param {type: \"slider\", min: 0, max: 49454}\n",
        "\n",
        "print(df_sorted.iloc[slider_value].cosine_similarity)\n",
        "show_pair(io.imread(df_sorted.iloc[slider_value].image_a_path), io.imread(df_sorted.iloc[slider_value].image_b_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZCbkvhoSkkI"
      },
      "source": [
        "### Choosing a threshold for deduplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_wFcR7o4FSL"
      },
      "outputs": [],
      "source": [
        "duplicates_df = df[(df.cosine_similarity > 0.9)]\n",
        "all_images = set(image_embeddings.keys())\n",
        "duplicate_set = set(duplicates_df.image_b_path.values)\n",
        "deduplicated_set = all_images - duplicate_set\n",
        "len(deduplicated_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCwQcoWg5kX7"
      },
      "outputs": [],
      "source": [
        "len(duplicate_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3YVlTL06SL7"
      },
      "outputs": [],
      "source": [
        "image_embeddings_dedup = {image_path : embedding for image_path, embedding in image_embeddings.items() if image_path not in duplicate_set}\n",
        "len(image_embeddings_dedup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_GcSCiiUFSp"
      },
      "outputs": [],
      "source": [
        "# Separate vectors and image filenames (for convenience)\n",
        "X = []\n",
        "images = []\n",
        "for image, embedding in image_embeddings_dedup.items():\n",
        "    X.append(embedding)\n",
        "    images.append(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go06aiN8_JCL"
      },
      "source": [
        "## Clustering Images\n",
        "\n",
        "Here we work with the K-medoids algorithm to select the most representative images in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf1vZD9xkbJh"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn-extra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiMeppxAsnFn"
      },
      "outputs": [],
      "source": [
        "from sklearn_extra.cluster import KMedoids\n",
        "\n",
        "\n",
        "kmedoids = KMedoids(n_clusters=10, random_state=0,\n",
        "                    init='k-medoids++', metric='cosine')\n",
        "\n",
        "kmedoids.fit(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nrq1ZGNRxvIk"
      },
      "outputs": [],
      "source": [
        "# Here we get the medoid images (representatives) and the number of images\n",
        "# that are most similar to them\n",
        "image_clusters = dict(zip(images, kmedoids.labels_))\n",
        "image_clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c1eacde"
      },
      "source": [
        "## 8. Additional Clustering and Visualization\n",
        "\n",
        "This part of the notebook contains additional code related to clustering and visualization of images. It includes techniques such as k-medoids clustering and visualizing clusters of similar images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm9LrMkAAqme"
      },
      "outputs": [],
      "source": [
        "images_array=np.array(images)\n",
        "representative_embeddings = kmedoids.cluster_centers_\n",
        "representative_images = images_array[kmedoids.medoid_indices_]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhqIKfM9OFId"
      },
      "outputs": [],
      "source": [
        "# Here we get the filenames of the most representative images\n",
        "representative_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FuDU0d7BW-v"
      },
      "outputs": [],
      "source": [
        "## Visualize representative images (medoids)\n",
        "f, axarr = plt.subplots(1, 10, figsize=(30,30))\n",
        "\n",
        "for i in range(10):\n",
        "  axarr[i].imshow(io.imread(folder_path /'paintings' /  representative_images[i]))\n",
        "  axarr[i].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiczsHxbrL_e"
      },
      "outputs": [],
      "source": [
        "len(representative_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8Ha5h0oguIL"
      },
      "outputs": [],
      "source": [
        "# @title Slider Tool to Visualize Every Neighborhood of the Ten Representative Images {run:'auto'}\n",
        "# @markdown * Do these images have duplicates?\n",
        "# @markdown * Do you find them representative?\n",
        "# @markdown * **What happens with a different threshold for deduplication?**\n",
        "\n",
        "slider_value = 4  # @param {type: \"slider\", min: 0, max: 9}\n",
        "plot_neighborhood(neighborhoods_dict[representative_images[slider_value]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25BGeI3KTDE8"
      },
      "source": [
        "## Choosing an 'Optimal' Number of Clusters Based on the Elbow Method\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBg-ZPRt5r8c"
      },
      "source": [
        "\n",
        "Choosing the \"\"right\"\" number of clusters is useful for achieving meaningful clustering results. In this part, we analyze different clustering options using the elbow method. Selecting a small number of clusters helps to summarize the dataset and in forming interpretable groups of similar images.\n",
        "\n",
        "We want to see find where the inflexion point happens.\n",
        "\n",
        "* **Distortion:** It is calculated as the average of the squared distances from the cluster centers of the respective clusters.\n",
        "\n",
        "* **Inertia:** It is the sum of squared distances of samples to their closest cluster center.\n",
        "\n",
        "\n",
        "Both of these methods usually give similar results. Both plots should show a decrease in intertia or distortion as we increase the number of clusters. We use the soft rule of choosing the number of clusters where we see \"an elbow\" (a big inflection) in both of these curves.\n",
        "\n",
        "In this set of plots, we see that the biggest inflection point happens at around 20 clusters, so it might be \"good enough\" to use 20 images to describe the dataset. **Think about this not as a hard rule, but as a heuristic to simplify and reduce the time of your explorations.**\n",
        "\n",
        "Read more about this [here](https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLPkWIIqMG3Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "from sklearn import metrics\n",
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "distortions = []\n",
        "inertias = []\n",
        "mapping1 = {}\n",
        "mapping2 = {}\n",
        "K = range(5, 100, 2)\n",
        "\n",
        "for k in K:\n",
        "    kmedoidModel = KMedoids(n_clusters=k, random_state=0, init='k-medoids++',\n",
        "                            metric='cosine')\n",
        "    kmedoidModel.fit(X)\n",
        "\n",
        "    distortions.append(sum(np.min(cdist(np.array(X), kmedoidModel.cluster_centers_,\n",
        "                      'cosine'),axis=1)))\n",
        "    inertias.append(kmedoidModel.inertia_)\n",
        "\n",
        "    mapping1[k] = sum(np.min(cdist(np.array(X), kmedoidModel.cluster_centers_,\n",
        "                 'cosine'),axis=1))\n",
        "    mapping2[k] = kmedoidModel.inertia_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMYSIXT3TiGI"
      },
      "outputs": [],
      "source": [
        "plt.plot(K, inertias, 'bx-')\n",
        "plt.xlabel('Values of K')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('The Elbow Method using Inertia')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZaJUyFkkQ4X"
      },
      "outputs": [],
      "source": [
        "plt.plot(K, distortions, 'bx-')\n",
        "plt.xlabel('Values of K')\n",
        "plt.ylabel('Distortion')\n",
        "plt.title('The Elbow Method using Distortion')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
